<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
# 《Watching a Small Portion could be as Good as Watching All: Towards Efficient Video Classification》 #
**IJCAI 2018**  
**RNNs(GRU,LSTM) & Reinforcement**  

&emsp; 这是一篇基于深度强化学习进行视频高效率分类的文章，文章提出了一种端到端的深度强化学习方法，通过所训练的智能体（Agent）做到像人类一样 **“Watching a Small Portion could be as Good as Watching All”** 从而快速对视频进行分类,其framework包含**Core network**(图A),**Fast forward network**(图B),**Adaptive stop network**(图C),**Baseline network**(图A),**Classification network**(图A)

![Framework](https://github.com/CSer-Tang-hao/Papers-Reading-Recording/blob/master/IJCAI2018/img/Fast_forward%2BAdaptive_stop.png)  
&emsp; 提高分类效率的核心思想: **Lower the number of processed frames**  
&emsp; **Motivation:** reduce the computational cost while retaining similar accuracy  
&emsp; (A)**Core network(LSTM or GRU):** (1)maintain an **internal state**（其汇总了Agent所观看的所有过去帧的历史信息）;(2)为Agent下一步该如何判断与行动提供了引导信息  
&emsp; (B)**Fast forward network:** 在观察一帧（由CNN输出的frame feature）之后，Agent通过从<a href="https://www.codecogs.com/eqnedit.php?latex=A\left&space;\{&space;-2s,-1s,&plus;1s,&plus;2s,&plus;4s,&plus;8s,&plus;16s&space;\right&space;\}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A\left&space;\{&space;-2s,-1s,&plus;1s,&plus;2s,&plus;4s,&plus;8s,&plus;16s&space;\right&space;\}" title="A\left \{ -2s,-1s,+1s,+2s,+4s,+8s,+16s \right \}" /></a>中选择动作<a href="https://www.codecogs.com/eqnedit.php?latex=a_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?a_{t}" title="a_{t}" /></a>来确定在其下一步观看的位置（可快进或慢退 ）  
&emsp; (C)**Adaptive stop network:** 这个网络受Agent控制用来决定何时停止watching videos并开始分类，这种自适应停止动作<a href="https://www.codecogs.com/eqnedit.php?latex=c_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?c_{t}" title="c_{t}" /></a>是一个二分类变量，<a href="https://www.codecogs.com/eqnedit.php?latex=c_{t}\it\in&space;C=&space;\left&space;\{&space;continue,stop&space;\right&space;\}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?c_{t}\it\in&space;C=&space;\left&space;\{&space;continue,stop&space;\right&space;\}" title="c_{t}\it\in C= \left \{ continue,stop \right \}" /></a>  
&emsp; (A)**Baseline network:** To reduce variance during training  
&emsp; (A)**Classification network:** 训练Agent为每个class做出二分类判断（positive or negative），当Adaptive stop network被触发后<a href="https://www.codecogs.com/eqnedit.php?latex=c_{T}=1" target="_blank"><img src="https://latex.codecogs.com/gif.latex?c_{T}=1" title="c_{T}=1" /></a>，
![Agent](https://github.com/CSer-Tang-hao/Papers-Reading-Recording/blob/master/IJCAI2018/img/Agent.png),根据**Core nerwork**的内部状态<a href="https://www.codecogs.com/eqnedit.php?latex=h_{T}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?h_{T}" title="h_{T}" /></a>开始输出prediction  
&emsp; **亮点**:文章基于深度强化学习的方法训练了一个智能体(Agent),这个智能体可以measuring confidence score进行判断与行动，对视频中一些不具判断信息的帧进行快进与跳过，对一些informative frame就slow down.快进与慢退的size也依靠Agent自主选择，当confident enough,Agent自行停止watching开始分类，这种方法的构思仿照人类判断的过程，并不需要看完整个video,靠一些key frame就可以做出分类判断，这样就可以Lower the number of processed frame，从而提高
分类的效率。  
&emsp; PDF：https://www.ijcai.org/proceedings/2018/0098.pdf
&emsp; Code：https://github.com/hehefan/video-classification   
&emsp; Datasets: **YouTobe-8M**  
&emsp; 注：之前看过16年的一篇CVPR"End to end learning of action detection from frame glimpses in videos",是用训练好的agent去做action detection,应该是近几年CV顶会上第一篇把**RL**用到Video& Action上，发现这篇IJCAI的构思与写法都是模仿了16年的CVPR,区别在于IJCAI **limit actions to a local range**,CVPR2016 **have no constraint on the action**
&emsp; Idea:这篇文章的“快进”、“倒退”思路让我想起了梯度下降法寻找最低点也是类似的过程，CVPR2018有篇文章就是使用自控的PID控制器改造了SGD，取得了较优的效果，这篇文章只是固定了一些“快进”与“慢退”的步长，如果加入了PID让这些步长不受约束，更加精细化，将PID控制器的反馈加入Agent的奖励与惩罚中，提高效率的话也可以先做一些简单的proposal再做classification,可以将这些方法用在video classification与action localization试试
