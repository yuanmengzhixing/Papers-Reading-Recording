# GAN & Zero-Shot Learning & Video Classfication

**《Visual Data Synthesis via GAN for Zero-Shot Video Classification》**
**IJCAI 2018**

Abstract：视频分类中的Zero-Shot Learning（ZSL）是一个有前途的研究方向，旨在应对视频类别爆炸性增长带来的挑战。大多数现有的方法通过学习视觉和语义空间之间的投影（projection）来利用看不见的相关性。然而，这种基于投影的范式不能充分利用数据分布中隐含的区分信息，而且常常遭受由“异质性差距”（heterogeneity gap）引起的信息退化问题。在本文中，作者通过GAN提出了一个可视化数据合成框架来解决这些问题。具体而言，利用语义知识和视觉分布来合成未见类别的视频特征，并将ZSL转化为具有综合特征的典型监督问题。首先，作者提出了多层次的语义推理来促进视频特征合成，通过特征层次和标签层次语义推断来捕获联合视觉语义分布所蕴含的判别信息。其次，作者提出匹配感知互信息相关来克服信息降级问题，该问题通过互信息捕获匹配和不匹配视觉语义对中的看不见的相关性，为 zero-shot 合成过程提供鲁棒的引导信号。在四个视频数据集上的实验结果表明，该文提出的方法可以显着提高 zero-shot 视频分类性能。  

**亮点:** 现有零样本学习方法采用特征嵌入的方式实现对语义信息的利用，从而建立从源域到目标域的语义关联。然而，这种方法忽略了数据分布中隐含的判别力信息，而且存在信息退化的问题，因此难以在复杂的视频零样本分类中取得好的效果。针对上述问题，本文提出了一种基于视频特征生成的零样本分类方法，利用对抗学习建立视频特征和语义信息之间的联合分布，借助生成的视频特征训练分类器以实现从零样本分类到有监督分类的转化。具体地，本文提出了一种对抗式双向合成的方法，在利用语义信息合成视频特征的同时，建立从视频特征到语义信息的推断，保证了所合成视频特征的判别力和鲁棒性。同时，为了应对视频特征和语义信息之间的“异构鸿沟”问题，本文提出了一种基于互信息的视觉-语义关联约束，从统计依赖的角度实现语义关联知识的迁移。实验结果证明了本文方法的有效性。

arXiv：https://arxiv.org/abs/1804.10073
注：最近Zero-Shot Learning的曝光量很足啊！GAN的魅力依旧那么强！

